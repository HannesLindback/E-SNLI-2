# E-SNLI-2

A replication of the E-SNLI experiments of Camburu et al. (2018) (Paper: https://arxiv.org/abs/1812.01193), where the goal is to get a language model to generate natural-language text sequences that explains why the model made a label classification prediciton. Instead of using LSTM-models as in the original paper, this replication uses transformers.

See Evaluating-the-Explanatory-Capabilities-of-Transformers.pdf for a more thorough description of the experiments.
